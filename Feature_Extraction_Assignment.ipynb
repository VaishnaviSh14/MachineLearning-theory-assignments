{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0008c3c0-4f1f-4d9f-92a7-80fe87301c7c",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application.\n",
    "\n",
    "Ans.\n",
    "\n",
    "Min-Max scaling, also known as normalization, is a data preprocessing technique used to rescale the features of a dataset to a specific range, typically between 0 and 1.\n",
    "\n",
    "It is mostly used in deep learning , it is useful when scale of the features varies widely , as it ensures all features have equal importance.\n",
    "\n",
    "Formula - x(scaled) = xi - min(x)/max(x)-min(x)\n",
    "\n",
    "For eg - \n",
    "Let us take a datset with a single feature age\n",
    "Age=[25,30,20,35,40]\n",
    " \n",
    "for x= 25\n",
    "x(scaled) = 25-20/40-20 = 0.25\n",
    "\n",
    "for x = 30\n",
    "x(scaled) = 30-20/40-20 = 0.5\n",
    "\n",
    "for x = 20\n",
    "x(scaled) = 20-20/40-20 = 0\n",
    "\n",
    "for x = 40\n",
    "x(scaled) = 40-20/40-20 = 1\n",
    "\n",
    "Scaled Age=[0.25,0.5,0,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a0c38-1410-45ca-8dd8-d8bc1326991d",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application.\n",
    "\n",
    "Ans.\n",
    "The Unit Vector considers the whole vector to be of unit length. Like Min-Max Scaling, this algorithm produces values between 0 and 1. \n",
    "\n",
    "Min-Max Scaling, on the other hand, is a standard data scaling technique used to transform features in a dataset to a specific range, typically between 0 and 1. The formula for Min-Max Scaling is:\n",
    "\n",
    "scaled_value = (original_value - min_value) / (max_value - min_value)\n",
    "\n",
    "EG - \n",
    "Suppose we have a vector x , which is a normal vector \n",
    "x-> = (3,4)\n",
    "what is the magnitude of this vector x\n",
    "||x->|| = √(3^2 + 4^2) = 5\n",
    "\n",
    "Now for finding the unit vector we have to divide each side by 5\n",
    "\n",
    "v̂ =  √((3/5)^2 + (4/5)^2) = 9/25 + 16 /25 = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c24a165-c659-495a-aa31-ba292f886b5c",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction?\n",
    "Ans.\n",
    "PCA is technique that transforms data into a lower dimensional space while dealing with high dimensional dataset, as it allows for easier visulization and analysis of data.\n",
    "While reducing the number of variables in the dataset, dimensionality reduction methods like PCA are used to preserve the most crucial data. The original variables are converted into a new set of variables called principal components, which are linear combinations of the original variables, by PCA in order to accomplish this.he term \"dimensionality\" describes the quantity of features or variables used in the research. It can be difficult to visualize and interpret the relationships between variables when dealing with high-dimensional data, such as datasets with numerous variables. While reducing the number of variables in the dataset, dimensionality reduction methods like PCA are used to preserve the most crucial data. The original variables are converted into a new set of variables called principal components, which are linear combinations of the original variables, by PCA in order to accomplish this.\n",
    "\n",
    " for eg - \n",
    "we have two data points no. of rooms and house size , now we want to do feature selection and select the top 1 feature\n",
    "Now if we se;ect only no.of rooms and we do not select house size , in this way we have a loss of information.\n",
    "Now using PCA we can covert from 2D to 1D , with less loss  of information\n",
    "\n",
    "We can create a PC line and join the points to that line, in this the variance will not be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1707a73f-c082-47e4-bf0b-7d91d0a545dd",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept.\n",
    "\n",
    "Ans.\n",
    "PCA and feature extraction are closely related concepts, and PCA can be used as a feature extraction technique.\n",
    "Feature extraction involves transforming the original features of a dataset into a new set of features (representations) that capture the most relevant information or patterns in the data.\n",
    "PCA achieves this by identifying the principal components, which are the directions of maximum variance in the data, and using them as the new extracted features.\n",
    "\n",
    "for eg - \n",
    "we have two data points no. of rooms and house size , now we want to do feature selection and select the top 1 feature\n",
    "Now if we se;ect only no.of rooms and we do not select house size , in this way we have a loss of information.\n",
    "Now using PCA we can covert from 2D to 1D , with less loss  of information\n",
    "\n",
    "We can create a PC line and join the points to that line, in this the variance will not be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a1b60d-09ed-404a-8f7a-44093788d72d",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data.\n",
    "\n",
    "Ans.\n",
    "Define the feature range:\n",
    "Decide on the desired range for the scaled features. In this case, we want to scale the features to a range between 0 and 1.\n",
    "\n",
    "Find the minimum and maximum values of each feature:\n",
    "For each feature (price, rating, delivery time), calculate its minimum and maximum values in the dataset.\n",
    "\n",
    "Apply Min-Max scaling formula:\n",
    "For each data point in the dataset, apply the Min-Max scaling formula to scale the feature values to the desired range (0 to 1). The formula is as follows:\n",
    "\n",
    "scaled_value = (original_value - min_value) / (max_value - min_value)\n",
    "\n",
    "where:\n",
    "\n",
    "\"original_value\" is the original value of the feature for a specific data point.\n",
    "\"min_value\" is the minimum value of the feature in the dataset.\n",
    "\"max_value\" is the maximum value of the feature in the dataset.\n",
    "\"scaled_value\" is the scaled value of the feature for that data point.\n",
    "Replace the original feature values with the scaled values:\n",
    "Update the dataset by replacing the original feature values with their corresponding scaled values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b221209c-966a-442b-8de8-094822281e9e",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset.\n",
    "\n",
    "Ans.\n",
    "Data Preprocessing: Ensure the dataset is preprocessed by handling missing values, normalizing or standardizing the features, and removing any irrelevant or redundant features that might not contribute to the prediction task.\n",
    "\n",
    "Define the Feature Set: Select the features that are relevant for predicting stock prices. These features can include financial data such as revenue, earnings, debt, and cash flow, as well as market trends like volume, moving averages, and technical indicators.\n",
    "\n",
    "Apply PCA: Once you have defined the feature set, you can apply PCA to reduce the dimensionality of the dataset. PCA will help you find a new set of uncorrelated features (principal components) that capture the most significant variance in the data.\n",
    "\n",
    "Determine the Number of Principal Components: Decide on the number of principal components to retain based on the amount of variance you want to preserve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33acb5c4-da2e-4d69-8925-20a991318e64",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1.\n",
    "\n",
    "Ans.\n",
    "\n",
    "x = [1,5,10,15,20]\n",
    "\n",
    "for x = 1\n",
    "x(scaled) = 1-1/20-1 = 0\n",
    "\n",
    "for x = 5\n",
    "x(scaled) = 5-1/20-1 = 0.21\n",
    "\n",
    "for x = 10\n",
    "x(scaled) = 10-1/20-1 = 0.47\n",
    "\n",
    "for x = 15\n",
    "x(scaled) = 15-1/20-1 = 0.73\n",
    "\n",
    "for x = 20\n",
    "x(scaled) = 20-1/20-1 = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c5d4e2-4585-46bb-a207-87a9ef65fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA.\n",
    "Ans.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Sample data for demonstration\n",
    "data = np.array([\n",
    "    [180, 75, 30, 1, 120],\n",
    "    [170, 65, 25, 0, 110],\n",
    "    [175, 70, 28, 1, 125],\n",
    "    [160, 60, 22, 0, 115],\n",
    "    [185, 80, 35, 1, 130]\n",
    "])\n",
    "\n",
    "# Step 1: Standardization\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(data)\n",
    "\n",
    "# Step 2: Apply PCA with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(standardized_data)\n",
    "\n",
    "# Explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Output the transformed data\n",
    "print(\"Original Data:\")\n",
    "print(data)\n",
    "print(\"\\nStandardized Data:\")\n",
    "print(standardized_data)\n",
    "print(\"\\nPrincipal Components:\")\n",
    "print(principal_components)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
