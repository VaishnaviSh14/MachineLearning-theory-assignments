{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89e1f599-8925-43f6-8cad-96b6c0c645f2",
   "metadata": {},
   "source": [
    "Q1. What is the difference between Ordinal Encoding and Label Encoding? Provide an example of when you\n",
    "might choose one over the other.\n",
    "\n",
    "Ans.\n",
    "\n",
    "Label Encoding and Ordinal Encoding are two techniques used to encode categorical data as numerical data.\n",
    "\n",
    "Label Encoding:\n",
    "Label encoding is a simple technique where each unique category in a categorical variable is assigned a unique integer label.\n",
    "\n",
    "Ordinal Encoding:\n",
    "Ordinal encoding is used when there is a meaningful order or hierarchy among the categories in the categorical variable. In this technique, each unique category is mapped to an integer value based on its relative position in the order.\n",
    "\n",
    "we might choose label encoding when dealing with categorical variables that have no inherent order or where preserving the relationships between categories is not important. For example, encoding colors, cities, or animal types would be suitable for label encoding.\n",
    "\n",
    "On the other hand, we should use ordinal encoding when dealing with categorical variables that have a clear order or hierarchy. Examples include educational levels, income levels (low, medium, high), or customer satisfaction ratings (low, medium, high).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47457607-a562-43c1-bd8d-d492230ce7ed",
   "metadata": {},
   "source": [
    "Q2. Explain how Target Guided Ordinal Encoding works and provide an example of when you might use it in\n",
    "a machine learning project.\n",
    "\n",
    "Ans.\n",
    "\n",
    "It is a technique used to encode categorical variables based on their relationship with the target variable. This encoding technique is useful when we have a categorical variable with a large number of unique categories, and we want to use this variable as a feature in our machine learning model.\n",
    "\n",
    "In Target Guided Ordinal Encoding, we replace each category in the categorical variable with a numerical value based on the mean or median of the target variable for that category. This creates a monotonic relationship between the categorical variable and the target variable, which can improve the predictive power of our model.\n",
    "\n",
    "Let's consider an example of a machine learning project in the context of customer churn prediction for a telecommunications company. The dataset contains several features, including a categorical variable \"Contract,\" which represents the type of contract the customers have with the company. The \"Contract\" variable has three categories: Month-to-Month, One Year, and Two Year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a540b833-2528-4be7-a819-ca4005ef98d8",
   "metadata": {},
   "source": [
    "Q3. Define covariance and explain why it is important in statistical analysis. How is covariance calculated?\n",
    "\n",
    "Ans.\n",
    "\n",
    "Covariance is a statistical measure that quantifies the degree to which two variables change together. It indicates the relationship between two variables and whether they tend to increase or decrease together.\n",
    "\n",
    "Covariance helps identify the direction and strength of the relationship between two variables. It is a crucial tool for understanding how changes in one variable are associated with changes in another, which is fundamental in data analysis and modeling.\n",
    "\n",
    "It is calculated using the formula - \n",
    "\n",
    "Cov(X, Y) = Σ [(Xᵢ - X̄) * (Yᵢ - Ȳ)] / (n - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db69de1-f7fa-470d-be92-b394b52f7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. For a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium,\n",
    "large), and Material (wood, metal, plastic), perform label encoding using Python's scikit-learn library.\n",
    "Show your code and explain the output.\n",
    "\n",
    "Ans.\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'Color':['red','green','blue'],\n",
    "    'Size':['small','medium','large'],\n",
    "    'Material':['wood','metal','plastic']\n",
    "\n",
    "                })\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_encoder = LabelEncoder()\n",
    "\n",
    "color = lb_encoder.fit_transform(df['Color'])\n",
    "size = lb_encoder.fit_transform(df['Size'])\n",
    "material = lb_encoder.fit_transform(df['Material'])\n",
    "\n",
    "print(color,size,material)\n",
    "\n",
    "\n",
    "Explanation:\n",
    "In the original DataFrame df, we have three categorical variables: 'Color', 'Size', and 'Material'.\n",
    "We use the LabelEncoder to encode each of these categorical columns separately.\n",
    "The label encoder assigns unique integer labels to each unique category in each column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceda205f-8674-4546-8db2-8433e24f1f4d",
   "metadata": {},
   "source": [
    "Q5. Calculate the covariance matrix for the following variables in a dataset: Age, Income, and Education\n",
    "level. Interpret the results.\n",
    "\n",
    "Ans.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Sample DataFrame with Age, Income, and Education Level\n",
    "data = {\n",
    "    'Age': [25, 30, 40, 35, 28],\n",
    "    'Income': [50000, 60000, 80000, 70000, 55000],\n",
    "    'Education Level': [12, 16, 18, 14, 15]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#Calculate the covariance matrix\n",
    "cov_matrix = df.cov()\n",
    "\n",
    "print(cov_matrix)\n",
    "\n",
    "\n",
    "Interpreting the results - \n",
    "Covariance between Age and Income:\n",
    "The covariance between Age and Income is 80000.0. This positive covariance suggests that as individuals' ages increase, their incomes tend to increase as well. It implies that there is a positive relationship between Age and Income, indicating that older individuals generally have higher incomes than younger ones.\n",
    "\n",
    "Covariance between Age and Education Level:\n",
    "The covariance between Age and Education Level is 6.5. This small positive covariance suggests a weak positive relationship between Age and Education Level. It means that, on average, as individuals' ages increase, their education level slightly increases as well. However, the covariance is relatively small, indicating that the correlation between these two variables is not very strong.\n",
    "\n",
    "Covariance between Income and Education Level:\n",
    "The covariance between Income and Education Level is 8333.3. This positive covariance suggests a positive relationship between Income and Education Level. It means that, on average, individuals with higher education levels tend to have higher incomes. However, it is important to note that the covariance value alone does not tell us about the strength of this relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b75aa-84b3-48ea-92e4-5f1febac7806",
   "metadata": {},
   "source": [
    "Q6. You are working on a machine learning project with a dataset containing several categorical\n",
    "variables, including \"Gender\" (Male/Female), \"Education Level\" (High School/Bachelor's/Master's/PhD),\n",
    "and \"Employment Status\" (Unemployed/Part-Time/Full-Time). Which encoding method would you use for\n",
    "each variable, and why?\n",
    "\n",
    "Ans.\n",
    "\n",
    "1. Gender (Binary Categorical Variable - Male/Female):\n",
    "Since \"Gender\" has only two categories, Male and Female, it is a binary categorical variable. For binary variables, the most common and straightforward encoding method is Label Encoding. Label encoding is a simple way to convert binary categorical variables into numerical representations without introducing additional dimensions.\n",
    "\n",
    "2. Education Level (Ordinal Categorical Variable - High School/Bachelor's/Master's/PhD):\n",
    "Since \"Education Level\" represents ordinal categories with a clear order (High School < Bachelor's < Master's < PhD), we can use Ordinal Encoding.\n",
    "\n",
    "\n",
    "3. Employment Status (Nominal Categorical Variable - Unemployed/Part-Time/Full-Time):\n",
    "For \"Employment Status,\" which represents nominal categories with no inherent order, one-hot encoding is more appropriate. One-hot encoding creates binary columns for each category, indicating the presence (1) or absence (0) of each category in the original variable. This avoids any ordinal assumptions and ensures that the machine learning model treats each category as a separate and unrelated feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c6ee8a-52ed-41b9-8196-1fb62b379b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. You are analyzing a dataset with two continuous variables, \"Temperature\" and \"Humidity\", and two\n",
    "categorical variables, \"Weather Condition\" (Sunny/Cloudy/Rainy) and \"Wind Direction\" (North/South/\n",
    "East/West). Calculate the covariance between each pair of variables and interpret the results.\n",
    "\n",
    "Ans.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Simulated data for illustration\n",
    "temperature = np.array([25, 28, 22, 30, 24])\n",
    "humidity = np.array([60, 65, 55, 70, 58])\n",
    "\n",
    "# Covariance between Temperature and Humidity\n",
    "cov_temp_humidity = np.cov(temperature, humidity)[0, 1]\n",
    "\n",
    "print(f\"Covariance between Temperature and Humidity: {cov_temp_humidity}\")\n",
    "\n",
    "\n",
    "#categorical variables\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create a contingency table (observed frequencies)\n",
    "observed = np.array([[observed_freq_sunny_north, observed_freq_sunny_south, observed_freq_sunny_east, observed_freq_sunny_west],\n",
    "                     [observed_freq_cloudy_north, observed_freq_cloudy_south, observed_freq_cloudy_east, observed_freq_cloudy_west],\n",
    "                     [observed_freq_rainy_north, observed_freq_rainy_south, observed_freq_rainy_east, observed_freq_rainy_west]])\n",
    "\n",
    "# Chi-squared Test for Independence\n",
    "chi2, p, dof, expected = chi2_contingency(observed)\n",
    "print(\"Chi-squared:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "\n",
    "# Cramér's V\n",
    "def cramers_v(confusion_matrix):\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = np.sum(confusion_matrix)\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k - 1) * (r - 1)) / (n - 1))\n",
    "    r_corr = r - ((r - 1)**2) / (n - 1)\n",
    "    k_corr = k - ((k - 1)**2) / (n - 1)\n",
    "    return np.sqrt(phi2corr / min((k_corr - 1), (r_corr - 1)))\n",
    "\n",
    "cramer_v = cramers_v(observed)\n",
    "print(\"Cramér's V:\", cramer_v)\n",
    "\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "If the p-value from the chi-squared test is small (usually less than 0.05), you can reject the null hypothesis and conclude that there is a significant association between the two categorical variables.\n",
    "The value of Cramér's V ranges from 0 to 1, where 0 indicates no association and 1 indicates a strong association. Intermediate values suggest varying degrees of association.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
