{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "469feaef-cb28-42db-9418-2f99ca9523da",
   "metadata": {},
   "source": [
    "Q1. What is the KNN algorithm?\n",
    "\n",
    "Ans.\n",
    "The K-nearest neighbors (KNN) algorithm is a non-parametric supervised learning algorithm that can be used for both classification and regression problems. It works by finding the k most similar training examples to a new data point and then assigning the new data point to the same class as the majority of its k nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f9c820-d41f-46bf-af7d-184f04bafd85",
   "metadata": {},
   "source": [
    "Q2. How do you choose the value of K in KNN?\n",
    "\n",
    "Ans.\n",
    "The most straightforward approach is to try different values of K and evaluate the model's performance using cross-validation or a validation dataset. You can plot the performance metrics (e.g., accuracy, F1-score, or mean squared error) against different K values and select the one that gives the best results. Be sure to consider a range of K values, such as odd numbers from 1 to a reasonable maximum.\n",
    "\n",
    "You can perform a grid search over a predefined range of K values to find the best K using cross-validation. This method is particularly useful if you're using KNN as a component within a larger machine learning pipeline, and you want to optimize hyperparameters collectively.\n",
    "\n",
    "Depending on the distance metric you use (e.g., Euclidean, Manhattan, or Minkowski), different values of K may work better. Experiment with various distance metrics and K values to find the best combination for your specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d108e47-a8ad-4bb9-b1aa-e4df22159917",
   "metadata": {},
   "source": [
    "Q3. What is the difference between KNN classifier and KNN regressor?\n",
    "\n",
    "Ans.\n",
    "\n",
    "KNN Classifier: Used for classification tasks, it assigns discrete class labels based on a majority vote from the nearest neighbors.\n",
    "\n",
    "KNN Regressor: Used for regression tasks, it predicts continuous numerical values by averaging the target values of the nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e232d8-7e62-4efd-b643-8b4db528f256",
   "metadata": {},
   "source": [
    "Q4. How do you measure the performance of KNN?\n",
    "\n",
    "Ans.\n",
    "\n",
    "The performance of the KNN algorithm can be measured using a variety of metrics, such as accuracy, precision, recall, and F1 score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe02207-c283-4d32-b90e-596f1dfc28c9",
   "metadata": {},
   "source": [
    "Q5. What is the curse of dimensionality in KNN?\n",
    "\n",
    "Ans.\n",
    "The curse of dimensionality is a phenomenon that occurs when the number of features in a dataset is much larger than the number of data points. This can make it difficult for the KNN algorithm to find the k most similar neighbors to a new data point, which can lead to decreased accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601e852b-2e5b-459b-96b3-5297afb7d090",
   "metadata": {},
   "source": [
    "Q6. How do you handle missing values in KNN?\n",
    "\n",
    "Ans.\n",
    "We can impute the missing values with the mean or median of the other values in the same feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ec403b-42ce-492c-9be4-841070908cef",
   "metadata": {},
   "source": [
    "Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for\n",
    "which type of problem?\n",
    "\n",
    "Ans.\n",
    "The KNN classifier and regressor have different strengths and weaknesses. The KNN classifier is typically better for problems where the classes are well-separated. The KNN regressor is typically better for problems where the output is continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf363fea-91af-4d59-9940-c708655ac226",
   "metadata": {},
   "source": [
    "Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks,\n",
    "and how can these be addressed?\n",
    "\n",
    "Ans.\n",
    "The KNN algorithm is a simple and easy-to-understand algorithm. It is also very versatile and can be used for both classification and regression tasks.\n",
    "However, the KNN algorithm can be computationally expensive, especially for large datasets.\n",
    "It can also be sensitive to noise and outliers.\n",
    "These weaknesses can be addressed by using a technique called feature selection to reduce the dimensionality of the dataset and by using a technique called data cleaning to remove noise and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac9e9e-e349-49e6-90b3-eb3384120c26",
   "metadata": {},
   "source": [
    "Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?\n",
    "\n",
    "Ans.\n",
    "\n",
    "The Euclidean distance is the most common distance metric used in KNN. It is calculated by taking the square root of the sum of the squared differences between the corresponding features of two data points. The Manhattan distance is another distance metric that can be used in KNN. It is calculated by summing the absolute differences between the corresponding features of two data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5834e48e-174c-4410-9627-99263012fd2f",
   "metadata": {},
   "source": [
    "Q10. What is the role of feature scaling in KNN?\n",
    "\n",
    "Ans.\n",
    "Feature scaling is a technique that is used to normalize the features in a dataset. This means that the features are all scaled to have a similar range of values. Feature scaling can help to improve the performance of the KNN algorithm by making it less sensitive to the scale of the features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
